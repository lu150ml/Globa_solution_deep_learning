# üåê Global Solution Deep Learning

[![Abrir no Google Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lu150ml/Globa_solution_deep_learning/blob/main/gs_deep_learning.ipynb)

Este reposit√≥rio documenta a Global Solution de Deep Learning desenvolvida para analisar o impacto da Intelig√™ncia Artificial no mercado de trabalho entre 2024 e 2030. O projeto utiliza ci√™ncia de dados, aprendizado de m√°quina e gera√ß√£o de linguagem para mapear riscos, agrupar perfis profissionais e fornecer recomenda√ß√µes personalizadas para o desenvolvimento de carreira.

## üß† Vis√£o Geral
- **Notebook principal:** `gs_deep_learning.ipynb`
- **Dom√≠nio:** an√°lise de empregabilidade diante da ado√ß√£o de IA.
- **Objetivo:** identificar grupos de profissionais com comportamentos semelhantes e gerar planos de a√ß√£o para cada perfil usando um modelo de linguagem hospedado na plataforma Groq.

## üìÅ Estrutura do Projeto
| Caminho | Descri√ß√£o |
| --- | --- |
| `gs_deep_learning.ipynb` | Notebook com todo o fluxo de prepara√ß√£o de dados, modelagem e interface. |
| `README.md` | Documento descritivo do projeto (este arquivo). |

> ‚ÑπÔ∏è O notebook foi desenhado para ser executado tanto no Google Colab quanto em ambiente local com Jupyter Notebook/Lab.

## üóÇÔ∏è Conjunto de Dados
- **Fonte:** [AI Impact on Job Market (2024-2030) ‚Äì Kaggle](https://www.kaggle.com/datasets/sahilislam007/ai-impact-on-job-market-20242030).
- **Arquivo esperado:** `ai_job_trends_dataset.csv` (deve estar dispon√≠vel na mesma pasta do notebook).
- **Vari√°veis-chave:**
  - Indicadores socioecon√¥micos (sal√°rio mediano, vagas abertas, diversidade etc.).
  - Impacto estimado da IA, risco de automa√ß√£o e formato de trabalho.
  - Status do emprego (vari√°vel-alvo utilizada para avaliar o modelo de clusteriza√ß√£o).

## üöÄ Pipeline Anal√≠tico
1. **üì• Importa√ß√£o de dados** ‚Äì leitura do CSV e inspe√ß√£o inicial (formato e colunas).
2. **üßπ Limpeza & an√°lise explorat√≥ria** ‚Äì contagem de valores ausentes e verifica√ß√£o de tipos.
3. **üî§ Codifica√ß√£o categ√≥rica** ‚Äì aplica√ß√£o de `LabelEncoder` para transformar textos em r√≥tulos num√©ricos.
4. **üìè Padroniza√ß√£o** ‚Äì normaliza√ß√£o de vari√°veis num√©ricas com `StandardScaler` para estabilizar o treinamento.
5. **‚úÇÔ∏è Split estratificado** ‚Äì divis√£o em conjuntos de treino e teste (`train_test_split`) preservando a distribui√ß√£o da classe alvo.
6. **üßÆ Pr√©-processamento combinado** ‚Äì uso de `ColumnTransformer` com `OneHotEncoder` para as categ√≥ricas e novo `StandardScaler` para as num√©ricas antes da clusteriza√ß√£o.
7. **üìä Clusteriza√ß√£o com K-Means** ‚Äì experimentos com 2 clusters, avalia√ß√£o por `silhouette_score` e compara√ß√£o com o status de emprego (accuracy, ARI e NMI).
8. **üß≠ Nomea√ß√£o sem√¢ntica dos clusters** ‚Äì mapeamento de cada cluster para r√≥tulos interpret√°veis:
   - `0 ‚Üí Profiss√µes Est√°veis / Adaptadas √† IA`
   - `1 ‚Üí Profiss√µes em Risco / Alta Automa√ß√£o`
9. **üßë‚Äçüíº Classifica√ß√£o de novos candidatos** ‚Äì fun√ß√£o `classify_candidate` encapsula pr√©-processamento, predi√ß√£o do cluster e retorno da classe predominante.
10. **ü§ñ Gera√ß√£o de recomenda√ß√µes** ‚Äì integra√ß√£o com a API compat√≠vel com OpenAI da Groq (modelo `llama-3.1-8b-instant`) para criar planos de carreira personalizados.
11. **üñ•Ô∏è Interface interativa** ‚Äì aplica√ß√£o Gradio que coleta os atributos do candidato e apresenta, em tempo real, sugest√µes de requalifica√ß√£o.
12. **üìâ Visualiza√ß√µes** ‚Äì redu√ß√£o de dimensionalidade com PCA para exibir os agrupamentos em 2D.

## üß© Principais Componentes do Notebook
- `classify_candidate(candidate_dict, preprocessor, model, cluster_names)` ‚Üí centraliza a l√≥gica de classifica√ß√£o e interpreta√ß√£o dos clusters.
- Bloco de integra√ß√£o com a **API Groq** (`OpenAI(base_url="https://api.groq.com/openai/v1")`) ‚Üí gera recomenda√ß√µes textuais estruturadas.
- Fun√ß√£o `gerar_recomendacoes_groq(...)` ‚Üí conecta o formul√°rio Gradio ao modelo de linguagem e retorna o texto exibido na interface.
- Interface `gr.Blocks` com sliders, caixas de texto e bot√µes estilizados para simular perfis profissionais.

## ‚öôÔ∏è Depend√™ncias Principais
| Categoria | Pacotes |
| --- | --- |
| Manipula√ß√£o de dados | `pandas`, `numpy` |
| Pr√©-processamento & Modelagem | `scikit-learn` (LabelEncoder, StandardScaler, KMeans, train_test_split, ColumnTransformer, OneHotEncoder, PCA, m√©tricas) |
| Visualiza√ß√£o | `matplotlib` |
| Interface | `gradio` |
| IA generativa | `openai` (SDK compat√≠vel com Groq) |

> ‚úÖ O Google Colab j√° inclui a maioria das depend√™ncias. Para execu√ß√£o local, utilize um ambiente virtual Python 3.9+.

## üíª Executando Localmente
1. **Clone o reposit√≥rio**
   ```bash
   git clone https://github.com/lu150ml/Globa_solution_deep_learning.git
   cd Globa_solution_deep_learning
   ```
2. **Crie e ative um ambiente virtual (opcional, mas recomendado)**
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # Linux/macOS
   .venv\Scripts\activate     # Windows
   ```
3. **Instale as depend√™ncias**
   ```bash
   pip install -r requirements.txt  # Caso crie um arquivo de requisitos
   ```
   Ou instale manualmente:
   ```bash
   pip install pandas numpy scikit-learn gradio openai matplotlib
   ```
4. **Disponibilize o dataset**
   - Fa√ßa o download no Kaggle.
   - Posicione o arquivo `ai_job_trends_dataset.csv` na raiz do projeto (mesmo diret√≥rio do notebook).
5. **Inicie o Jupyter Notebook/Lab**
   ```bash
   jupyter notebook
   ```
   Abra `gs_deep_learning.ipynb` e execute as c√©lulas em sequ√™ncia.

## ‚òÅÔ∏è Execu√ß√£o no Google Colab
1. Clique no badge "Abrir no Google Colab" no topo deste README.
2. Fa√ßa upload do dataset ou monte o Google Drive contendo o arquivo CSV.
3. Configure a vari√°vel de ambiente da API (ver se√ß√£o abaixo) antes de executar a interface Gradio.

## üîê Configura√ß√£o da Chave da API Groq
A integra√ß√£o com o modelo `llama-3.1-8b-instant` exige uma chave v√°lida da Groq.

```python
from openai import OpenAI
import os

client = OpenAI(
    base_url="https://api.groq.com/openai/v1",
    api_key=os.environ["GROQ_API_KEY"],
)
```

1. Crie um arquivo `.env` (opcional) com `GROQ_API_KEY=suachave` ou exporte a vari√°vel diretamente no terminal:
   ```bash
   export GROQ_API_KEY="suachave"
   ```
2. Reinicie o kernel/notebook ap√≥s definir a vari√°vel.

## üñ•Ô∏è Interface Gradio
- **T√≠tulo e descri√ß√£o** orientam o usu√°rio sobre o simulador.
- **Entradas**: campos de texto, n√∫meros e sliders que representam atributos profissionais (setor, impacto da IA, sal√°rios, risco de automa√ß√£o, diversidade etc.).
- **Sa√≠da**: caixa de texto expans√≠vel exibindo as recomenda√ß√µes geradas pela API Groq.
- **Execu√ß√£o**: a chamada `demo.launch(share=True)` habilita um link p√∫blico tempor√°rio.

## üìà M√©tricas e Avalia√ß√µes
- **Silhouette Score** para verificar a separa√ß√£o dos clusters.
- **Accuracy, Adjusted Rand Index (ARI) e Normalized Mutual Information (NMI)** comparando os clusters com o `Job Status` conhecido.
- **Classification Report** para inspe√ß√£o das classes predominantes.

Os valores exatos dependem do dataset e dos par√¢metros utilizados durante a execu√ß√£o.

## üß™ Boas Pr√°ticas
- Execute o pr√©-processamento completo antes de avaliar a clusteriza√ß√£o.
- Valide o desempenho com diferentes sementes (`random_state`) e n√∫mero de clusters, caso deseje explorar varia√ß√µes.
- Armazene os objetos treinados (`pre_km`, `km_final`, `cluster_names`) para reutilizar no m√≥dulo de recomenda√ß√µes.

## üë• Equipe
- Lu√≠s Henrique Ribeiro ‚Äì RM559100
- Matheus Henrique Portapilla ‚Äì RM554481
- Ryan Sales Fernandes ‚Äì RM558397

## üì¨ Suporte
D√∫vidas, sugest√µes ou melhorias? Abra uma issue no reposit√≥rio ou entre em contato com a equipe.

---

‚úâÔ∏è **Contribui√ß√µes s√£o bem-vindas!** Fa√ßa um fork, crie uma branch e envie um pull request descrevendo suas mudan√ßas.
